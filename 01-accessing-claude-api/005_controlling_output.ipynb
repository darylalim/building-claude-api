{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed19c21-ea29-49fe-9403-ebd4155d766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a5599-f094-432b-849a-99c931b904be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af347b63-d006-4307-a46f-733dad2e74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an API client\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0730ae-300e-4b94-baaf-23335664dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "    \n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "    \n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be37fae-ab21-457f-990b-7a963ce4fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant message prefilling\n",
    "messages = []\n",
    "\n",
    "add_user_message(\n",
    "    messages, \n",
    "    \"Is tea or coffee better at breakfast?\"\n",
    ")\n",
    "\n",
    "add_assistant_message(\n",
    "    messages,\n",
    "    \"Neither is very good because\"\n",
    ")\n",
    "\n",
    "answer = chat(messages)\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea41a8-ee01-4baa-8ef5-d395f36ac13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop sequences\n",
    "messages = []\n",
    "\n",
    "add_user_message(\n",
    "    messages, \n",
    "    \"Count from 1 to 10\"\n",
    ")\n",
    "\n",
    "answer = chat(messages, stop_sequences=[\", 5\"])\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d39dc-30e6-48ab-8df4-c68f11daf96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured data\n",
    "messages = []\n",
    "\n",
    "add_user_message(messages, \"Generate a very short event bridge rule as json\")\n",
    "add_assistant_message(messages, \"```json\")\n",
    "\n",
    "text = chat(messages, stop_sequences=[\"```\"])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6a507-f357-4da2-8bc3-760bf40416d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712fa99-7f9e-45c8-b8a3-61a4f3fdf24e",
   "metadata": {},
   "source": [
    "## Exercise!\n",
    "\n",
    "- Use message prefilling and stop sequences *only* to get three different commands in a single response\n",
    "- There shouldn't be any comments or explanation\n",
    "- Hint: message prefilling isn't limited to just characters like ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304933d-f4bd-4e4d-be6d-81168e804592",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate three different sample AWS CLI commands. Each should be very short.\n",
    "\"\"\"\n",
    "\n",
    "add_user_message(messages, prompt)\n",
    "add_assistant_message(messages, \"Here are all three commands in a single block without any comments:\\n```bash\")\n",
    "\n",
    "text = chat(messages, stop_sequences=[\"```\"])\n",
    "text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c77bfb-83b1-47d1-8f26-976cad9fcb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd382dd3-d343-4c94-8f04-5fd6c4720121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
